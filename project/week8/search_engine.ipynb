{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453dace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요.I am loopy\n",
      "rank\tIndex\tscore\tsentence\n",
      "1\t251\t0.3333\tI am nine years old.\n",
      "2\t623\t0.1818\tI am sorry for my late reply to your letter.\n",
      "3\t160\t0.1667\tI just wanted you to know how proud I am of Bobby.\n",
      "4\t405\t0.1429\tI felt sorry for it.\n",
      "5\t516\t0.1429\tI just got your flower.\n",
      "6\t388\t0.125\tI even have my feet pickled!\n",
      "7\t556\t0.125\tI'm glad I let it go.\n",
      "8\t718\t0.125\tI saw an accident this morning.\n",
      "9\t62\t0.1111\tI insisted he take a hearing test.\n",
      "10\t383\t0.1111\tI don't want to shut them out.\"\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    preprocessed_sentence = sentence.strip().split(\" \")\n",
    "    return preprocessed_sentence\n",
    "\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = []    \n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines()\n",
    "    for line in lines:\n",
    "        tokens = preprocess(line) # lines의 각 아이템들의 앞뒤 공백을 제거하고 아이템 내의 공백을 기준으로 나눔\n",
    "        file_tokens_pairs.append(tokens) # 빈 리스트에 tokens, 즉, 한 단어씩을 추가\n",
    "    return file_tokens_pairs\n",
    "\n",
    "\n",
    "def cals_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {}\n",
    "    \n",
    "    for i in range(len(preprocessed_sentences)): # 찾을 문장의 대소문자 구분없이 처리하기 위함\n",
    "        sentence = []\n",
    "        for word in preprocessed_sentences[i]:\n",
    "            sentence.append(word.lower()) # 소문자로 변환하여 sentence에 저장\n",
    "        file_token_set = set(sentence)\n",
    "        all_tokens = preprocessed_query | file_token_set # all_tokens는 쿼리토큰셋과 파일토큰셋의 합집합\n",
    "        same_tokens = preprocessed_query & file_token_set # same_tokens는 쿼리토큰셋과 파일토큰셋의 교집합\n",
    "        similarity = len(same_tokens) / len(all_tokens) # 유사도를 계산하기 위해 일치하는 토큰 수를 전체 토큰 수로 나눔\n",
    "        similarity = round(similarity, 4) # 유사도 점수가 너무 길어지는걸 방지하기 위해 소수점 4자리까지 나타내도록 수정\n",
    "        score_dict[i] = similarity\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "# 1. Indexing\n",
    "## https://github.com/jungyeul/korean-parallel-corpora\n",
    "file_name = \"jhe-koen-dev.en\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요.\").lower()\n",
    "preprocessed_query = preprocess(query) # query의 앞뒤 공백을 제거하고, query 내의 공백을 기준으로 나눔\n",
    "query_token_set = set(preprocessed_query) # 위의 preprocessed_query에서 중복된 항목을 하나로 병합\n",
    "\n",
    "# 3. Calculate similarities based on a same token set\n",
    "# cals_similarity 함수를 호출하여 query_token_set과 file_tokens_set 사이의 유사도를 계산하고 결과를 score_dict에 저장\n",
    "score_dict = cals_similarity(query_token_set, file_tokens_pairs)\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "# score_dict를 유사도 점수에 따라 내림차순(기본세팅인 오름차순의 reverse=True)으로 정렬하여 sorted_score_list에 저장\n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. Print the result\n",
    "# 가장 높은 유사도가 0.0인 경우 \"There is no similar sentence.\" 출력\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else: # 가장 높은 유사도가 0.0이 아닌 경우\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\") # rank, Index, score, sentence를 \\t로 구분\n",
    "    rank = 1\n",
    "    for i, score in sorted_score_list:\n",
    "        # 결과를 rank, index, score 및 해당 문장으로 출력, 각 요소는 \\t로 구분\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10: # rank가 10일 경우\n",
    "            break # 반복문 탈출\n",
    "        rank = rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173030c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
